{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b8db08c2-e592-4143-8a42-c3bf4b39e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c1dd53f4-c77b-430d-aece-7408265c9edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./mnist_train.csv')\n",
    "test_data = pd.read_csv('./mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a446cbd1-7105-4e87-b1e4-24c08ed449e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(train_data, test_data):\n",
    "    X_train = train_data.drop(['label'],axis=1)\n",
    "    y_train = train_data['label']\n",
    "    X_test = test_data.drop(['label'],axis=1)\n",
    "    y_test = test_data['label']\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def to_numpy(X_train, y_train, X_test, y_test):\n",
    "    X_train = X_train.to_numpy()\n",
    "    y_train = y_train.to_numpy()\n",
    "    X_test = X_test.to_numpy()\n",
    "    y_test = y_test.to_numpy()\n",
    "    return X_train, y_train, X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c93a8d3-ae62-410b-bdd6-0c577a866cb6",
   "metadata": {},
   "source": [
    "# Hebbian Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "328d100b-2866-4eac-8f38-c0a9e12d1e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hebbian_NN():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.w = np.zeros((output_size, input_size + 1))\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        for i,row in enumerate(X_train):\n",
    "            label = y_train[i]\n",
    "            x = np.append(row,1)\n",
    "            self.w[label] = self.w[label] + x #* label\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.append(x,1)\n",
    "        outputs = np.dot(self.w,x)\n",
    "        return np.argmax(outputs)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        preds = np.array([])\n",
    "        for x in X_test:\n",
    "            pred = self.predict(x)\n",
    "            preds = np.append(preds, pred)\n",
    "            \n",
    "        print(f'accuracy: {(preds == y_test).sum() / len(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1561b42d-cfcd-4e82-8693-49bd6829b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(train_data, test_data)\n",
    "X_train, y_train, X_test, y_test = to_numpy(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "198b52e3-e52b-4684-859a-a88f7b9b9a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6804\n"
     ]
    }
   ],
   "source": [
    "heb1 = Hebbian_NN(784, 10)\n",
    "heb1.fit(X_train, y_train)\n",
    "heb1.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68405782-6938-4f8d-a643-c97ec60542bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(train_data, test_data)\n",
    "X_train = X_train.apply(lambda col: col.map(lambda x: 1 if x > 0 else 0))\n",
    "X_test = X_test.apply(lambda col: col.map(lambda x: 1 if x > 0 else 0))\n",
    "X_train, y_train, X_test, y_test = to_numpy(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85ee9554-713f-4502-a538-e2e6c541bae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6137\n"
     ]
    }
   ],
   "source": [
    "model2 = Hebbian_NN(784, 10)\n",
    "model2.fit(X_train, y_train)\n",
    "model2.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6dac8dda-4f1e-4fbb-be50-e254b344081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(train_data, test_data)\n",
    "X_train = X_train.apply(lambda col: col.map(lambda x: x if x > 0 else -1))\n",
    "X_test = X_test.apply(lambda col: col.map(lambda x: x if x > 0 else -1))\n",
    "X_train, y_train, X_test, y_test = to_numpy(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfc29208-cd36-422a-a36b-e1cb7aa78dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6825\n"
     ]
    }
   ],
   "source": [
    "model3 = Hebbian_NN(784, 10)\n",
    "model3.fit(X_train, y_train)\n",
    "model3.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "931bd239-b287-47bb-ade6-50da12b52b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(train_data, test_data)\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_train, y_train, X_test, y_test = to_numpy(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f426cb74-9aee-4cd1-99c1-3b38a337db79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6808\n"
     ]
    }
   ],
   "source": [
    "model4 = Hebbian_NN(784, 10)\n",
    "model4.fit(X_train, y_train)\n",
    "model4.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51da7602-aa16-4677-84f3-ce4c564730aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6451\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(train_data, test_data)\n",
    "X_train = X_train - X_train.mean()\n",
    "X_test = X_test - X_train.mean()\n",
    "X_train, y_train, X_test, y_test = to_numpy(X_train, y_train, X_test, y_test)\n",
    "model5 = Hebbian_NN(784, 10)\n",
    "model5.fit(X_train, y_train)\n",
    "model5.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "094ec12c-9d4f-41a6-aa2d-f9c6c4d628a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(train_data, test_data)\n",
    "X_train = X_train - X_train.mean()\n",
    "X_test = X_test - X_train.mean()\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(whiten=True)\n",
    "X_train = pd.DataFrame(pca.fit_transform(X_train))\n",
    "X_test = pd.DataFrame(pca.transform(X_test))\n",
    "\n",
    "X_train, y_train, X_test, y_test = to_numpy(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef4bca04-dbc0-4b55-a576-9d8870879ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8096\n"
     ]
    }
   ],
   "source": [
    "model6 = Hebbian_NN(784, 10)\n",
    "model6.fit(X_train, y_train)\n",
    "model6.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33149db-1dd5-471b-a297-3ca035ca702b",
   "metadata": {},
   "source": [
    "# Perseptron Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b8cfe9d-3576-4816-9886-c18cb1d37f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(train_data, test_data)\n",
    "X_train, y_train, X_test, y_test = to_numpy(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e25ae8b-2f73-4c9c-b187-30ad3e0f8777",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perseptron_NN():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.w = np.zeros((output_size, input_size + 1))\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        for i,row in enumerate(X_train):\n",
    "            label = y_train[i]\n",
    "            if self.predict(row) != label:\n",
    "                self.w[label] = self.w[label] + np.append(row,1) #* label\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.append(x,1)\n",
    "        outputs = np.dot(self.w,x)\n",
    "        return np.argmax(outputs)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        preds = np.array([])\n",
    "        for x in X_test:\n",
    "            pred = self.predict(x)\n",
    "            preds = np.append(preds, pred)\n",
    "            \n",
    "        print(f'accuracy: {(preds == y_test).sum() / len(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6081375b-3f8e-4f07-8d0a-9f0844a7aa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8668\n"
     ]
    }
   ],
   "source": [
    "pr1 = Perseptron_NN(784, 10)\n",
    "pr1.fit(X_train, y_train)\n",
    "pr1.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062d9e31-1f3c-4b39-be25-c9750a87d697",
   "metadata": {},
   "source": [
    "# Adaline Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e7ce8698-d4c0-4634-874f-e38bfa027f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaline:\n",
    "    def __init__(self, learning_rate=0.0001, epochs=50):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features) \n",
    "        self.bias = 0 \n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            linear_output = np.dot(X, self.weights) + self.bias\n",
    "            errors = y - linear_output\n",
    "            \n",
    "            self.weights += self.learning_rate * np.dot(X.T, errors) / n_samples\n",
    "            self.bias += self.learning_rate * np.mean(errors)\n",
    "            \n",
    "            loss = np.mean(errors ** 2) / 2\n",
    "            print(f\"Epoch {epoch + 1}/{self.epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        return np.where(linear_output >= 0, 1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9a3f7959-a357-462c-8dcb-9ed1e06b4d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(train_data, test_data)\n",
    "X_train, y_train, X_test, y_test = to_numpy(X_train, y_train, X_test, y_test)\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "y_train = np.where(y_train == 0, -1, 1)\n",
    "y_test = np.where(y_test == 0, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f1ad928-6a59-4698-aab7-2d969e7d4a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.5000\n",
      "Epoch 2/50, Loss: 0.4978\n",
      "Epoch 3/50, Loss: 0.4956\n",
      "Epoch 4/50, Loss: 0.4934\n",
      "Epoch 5/50, Loss: 0.4912\n",
      "Epoch 6/50, Loss: 0.4891\n",
      "Epoch 7/50, Loss: 0.4869\n",
      "Epoch 8/50, Loss: 0.4848\n",
      "Epoch 9/50, Loss: 0.4827\n",
      "Epoch 10/50, Loss: 0.4806\n",
      "Epoch 11/50, Loss: 0.4785\n",
      "Epoch 12/50, Loss: 0.4765\n",
      "Epoch 13/50, Loss: 0.4744\n",
      "Epoch 14/50, Loss: 0.4724\n",
      "Epoch 15/50, Loss: 0.4704\n",
      "Epoch 16/50, Loss: 0.4684\n",
      "Epoch 17/50, Loss: 0.4664\n",
      "Epoch 18/50, Loss: 0.4644\n",
      "Epoch 19/50, Loss: 0.4625\n",
      "Epoch 20/50, Loss: 0.4605\n",
      "Epoch 21/50, Loss: 0.4586\n",
      "Epoch 22/50, Loss: 0.4567\n",
      "Epoch 23/50, Loss: 0.4548\n",
      "Epoch 24/50, Loss: 0.4529\n",
      "Epoch 25/50, Loss: 0.4510\n",
      "Epoch 26/50, Loss: 0.4492\n",
      "Epoch 27/50, Loss: 0.4473\n",
      "Epoch 28/50, Loss: 0.4455\n",
      "Epoch 29/50, Loss: 0.4437\n",
      "Epoch 30/50, Loss: 0.4419\n",
      "Epoch 31/50, Loss: 0.4401\n",
      "Epoch 32/50, Loss: 0.4383\n",
      "Epoch 33/50, Loss: 0.4365\n",
      "Epoch 34/50, Loss: 0.4348\n",
      "Epoch 35/50, Loss: 0.4330\n",
      "Epoch 36/50, Loss: 0.4313\n",
      "Epoch 37/50, Loss: 0.4296\n",
      "Epoch 38/50, Loss: 0.4279\n",
      "Epoch 39/50, Loss: 0.4262\n",
      "Epoch 40/50, Loss: 0.4245\n",
      "Epoch 41/50, Loss: 0.4229\n",
      "Epoch 42/50, Loss: 0.4212\n",
      "Epoch 43/50, Loss: 0.4196\n",
      "Epoch 44/50, Loss: 0.4180\n",
      "Epoch 45/50, Loss: 0.4164\n",
      "Epoch 46/50, Loss: 0.4148\n",
      "Epoch 47/50, Loss: 0.4132\n",
      "Epoch 48/50, Loss: 0.4116\n",
      "Epoch 49/50, Loss: 0.4100\n",
      "Epoch 50/50, Loss: 0.4085\n",
      "Accuracy: 90.20%\n"
     ]
    }
   ],
   "source": [
    "adaline = Adaline(learning_rate=0.0001, epochs=50)\n",
    "adaline.fit(X_train, y_train)\n",
    "y_pred = adaline.predict(X_test)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ec87b1-adf9-4b72-83d7-e62f0c53fdf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
